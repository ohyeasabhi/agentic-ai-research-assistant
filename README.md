ğŸ§  Agentic AI Research Assistant (Local, Multi-Agent System)

A local, agentic AI research assistant built from scratch using Python and Streamlit, powered by open-source LLMs via Ollama.
This project demonstrates core Agentic AI concepts such as planning, tool usage, self-critique, semantic memory, and evaluation â€” all without paid APIs.

ğŸš€ What This Project Is

This is not a chatbot.

It is a goal-driven agentic system that:

Plans how to approach a task

Breaks it into steps

Uses tools when needed

Reviews its own output

Improves results through retries

Remembers past knowledge semantically

Everything runs locally.

âœ¨ Key Features
ğŸ§© Agentic Architecture

Planner Agent â€“ breaks a topic into subtopics

Researcher Agent â€“ gathers information per subtopic

Writer Agent â€“ synthesizes a structured report

Critic Agent â€“ evaluates quality and triggers retries

ğŸ›  Tool Usage

The agent can autonomously decide to use:

Persistent memory (save important knowledge)

Calculator (for numerical reasoning)

File writer (export results)

ğŸ§  Memory Systems

Persistent Memory â€“ topic â†’ summary (JSON)

Semantic Memory â€“ meaning-based recall using embeddings + FAISS

ğŸ” Self-Critique Loop

The agent reviews its own output

Retries generation if quality is insufficient

Stops when an acceptable result is achieved

ğŸ“Š Evaluation & Logging

Each agent run logs:

Topic

Model used

Number of retries

Tools used

Execution time

Stored locally in agent_logs.json.

ğŸ“„ Export

Download final research as Markdown

Download final research as PDF

ğŸ§  Why This Is Agentic AI (Not Just LLM Usage)

This project demonstrates agent behavior, not prompt engineering.

âœ” Planning before acting
âœ” Role-based reasoning
âœ” Tool awareness & execution
âœ” Self-evaluation & retries
âœ” Long-term semantic memory
âœ” Observable decision metrics

These are the core building blocks of Agentic AI systems.

ğŸ— Architecture Overview
User (Streamlit UI)
   â†“
Agent Controller (app.py)
   â†“
Planner Agent
   â†“
Researcher Agent
   â†“
Writer Agent
   â†“
Critic Agent (retry loop)
   â†“
Tool Router
   â†“
Memory + Tools
   â†“
Semantic Vector Store (FAISS)
   â†“
Evaluation Logger


Each agent has one responsibility, coordinated by a central controller.

ğŸ›  Tech Stack

Python

Streamlit â€“ UI & orchestration

Ollama â€“ local LLM runtime

Mistral / LLaMA / Neural-Chat â€“ open-source LLMs

FAISS â€“ vector similarity search

Sentence Transformers â€“ embeddings

ReportLab â€“ PDF generation

All components are free and local.

â–¶ï¸ How to Run Locally
1ï¸âƒ£ Install dependencies
pip install streamlit sentence-transformers faiss-cpu reportlab

2ï¸âƒ£ Install and pull LLM
ollama pull mistral

3ï¸âƒ£ Run the app
python -m streamlit run app.py

ğŸ§ª Example Use Cases

Research technical topics

Summarize complex subjects

Demonstrate agentic reasoning

Experiment with local LLMs

Study memory-augmented AI systems

ğŸ“ Project Structure
ai-research-assistant/
â”‚
â”œâ”€â”€ app.py                # Agent controller & UI
â”œâ”€â”€ research_agent.py     # Planner, Researcher, Writer, Critic agents
â”œâ”€â”€ tools.py              # Tool implementations & routing
â”œâ”€â”€ semantic_memory.py    # Vector memory (FAISS)
â”œâ”€â”€ agent_logger.py       # Evaluation & metrics logging
â”œâ”€â”€ README.md
â”œâ”€â”€ agent_logs.json       # (auto-generated)

ğŸ“Œ What This Project Demonstrates

Understanding of Agentic AI concepts

Clean separation of concerns

Local LLM deployment

Memory-augmented reasoning

Practical AI system design

Explainable, interview-ready architecture

ğŸ§  Author Note

This project was built for educational and portfolio purposes, focusing on clarity, correctness, and real-world agent design rather than over-engineering or frameworks.

â­ If Youâ€™re Reviewing This Repo

This project intentionally avoids:

Paid APIs

Heavy frameworks

Black-box abstractions

The goal is to demonstrate understanding, not hide logic.